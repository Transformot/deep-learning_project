{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "226ffa5279a971b5",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Recurrent Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e43d8f94dc514c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Importation librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T13:07:22.254769Z",
     "start_time": "2024-05-20T13:07:05.832326Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.utils import normalize, plot_model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense\n",
    "from tensorflow.keras import models, callbacks\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18d9be17d1fd322",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Data import and display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f046e5a88eefc36",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T13:08:15.066697Z",
     "start_time": "2024-05-20T13:08:15.046561Z"
    }
   },
   "outputs": [],
   "source": [
    "# Data recovery\n",
    "train_data = np.loadtxt('data/ECG200_TRAIN.tsv', delimiter='\\t')\n",
    "test_data = np.loadtxt('data/ECG200_TEST.tsv', delimiter='\\t')\n",
    "\n",
    "# Show first time series\n",
    "print(\"health:\", train_data[0,0])\n",
    "print(train_data[0,1:])\n",
    "\n",
    "# Show data dimensions\n",
    "print(\"Dimensions des données d'entrainnement:\", train_data.shape)\n",
    "print(\"Dimensions des données de test:\", test_data.shape)\n",
    "\n",
    "# Show first 5 time series\n",
    "nb_series_a_afficher = 5\n",
    "plt.figure(figsize=(27, 7))\n",
    "for i in range(nb_series_a_afficher):\n",
    "    serie_temporelle = train_data[i, 1:]\n",
    "    etat_sante = train_data[i, 0]\n",
    "    \n",
    "    plage_temps = range(len(serie_temporelle))\n",
    "    \n",
    "    plt.subplot(2, nb_series_a_afficher, i+1)\n",
    "    plt.plot(plage_temps, serie_temporelle, label='Série temporelle')\n",
    "    plt.xlabel('Temps')\n",
    "    plt.ylabel('Valeurs')\n",
    "    plt.title(f'Série temporelle {i+1} (Santé: {\"Bon\" if etat_sante == -1 else \"Mauvais\"})')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8952b43569ed0bb",
   "metadata": {},
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b3bc14896c5c0d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T13:08:17.976099Z",
     "start_time": "2024-05-20T13:08:17.963697Z"
    }
   },
   "outputs": [],
   "source": [
    "# Normalizer classes\n",
    "train_data[train_data[:, 0] == -1, 0] = 0\n",
    "test_data[test_data[:, 0] == -1, 0] = 0\n",
    "\n",
    "# Separation of training and testing data\n",
    "X_train, y_train = train_data[:, 1:], train_data[:, 0]\n",
    "X_test, y_test = test_data[:, 1:], test_data[:, 0]\n",
    "\n",
    "# Normalize time series between 0 and 1 independently of each other\n",
    "X_train = normalize(X_train, axis=1)\n",
    "X_test = normalize(X_test, axis=1)\n",
    "\n",
    "# Display first data\n",
    "print(\"health:\", y_train[0])\n",
    "print(X_train[0])\n",
    "print(\"Dimensions des données d'entrainnement:\", (X_train.shape, y_train.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbedfee8",
   "metadata": {},
   "source": [
    "## Choice of Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432873e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layers hyperparameters\n",
    "timesteps = 1\n",
    "nb_neurons = 8\n",
    "nb_classes = 1\n",
    "final_activation = 'sigmoid'\n",
    "\n",
    "# Compil hyperparameters\n",
    "optimizer_algo = 'adam'\n",
    "cost_function = 'binary_crossentropy'\n",
    "\n",
    "# Execution hyperparameters\n",
    "nb_epochs = 500\n",
    "mini_batch_size = 32\n",
    "percentage_of_train_as_validation = 0.2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102278c56ac89575",
   "metadata": {},
   "source": [
    "## Model compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331fdd7d2789c9d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T13:08:22.396808Z",
     "start_time": "2024-05-20T13:08:21.450997Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Input\n",
    "input_shape = (96,1)\n",
    "input_layer = Input(input_shape)\n",
    "\n",
    "# Hidden block\n",
    "lstm_layer = LSTM(units=nb_neurons)(input_layer)\n",
    "\n",
    "# Output\n",
    "output_layer = Dense(units=nb_classes, activation=final_activation)(lstm_layer)\n",
    "\n",
    "model_rnn = models.Model(inputs=input_layer, outputs=output_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a01a067eec2e9",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Model compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc37593028bd6d3a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T13:08:24.187674Z",
     "start_time": "2024-05-20T13:08:23.989196Z"
    }
   },
   "outputs": [],
   "source": [
    "model_rnn.compile(loss=cost_function, optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model_rnn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2386a065f3e54df9",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175385fb6430db0f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T13:09:04.443149Z",
     "start_time": "2024-05-20T13:08:25.495010Z"
    }
   },
   "outputs": [],
   "source": [
    "# Specify the model checkpoint (to save the best model for each epoch)\n",
    "model_checkpoint = callbacks.ModelCheckpoint('best_model_RNN.keras', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "# Start training\n",
    "start_training = time.time()\n",
    "history = model_rnn.fit(X_train, y_train,\n",
    "                    batch_size=mini_batch_size, \n",
    "                    epochs=nb_epochs,\n",
    "                    validation_split=percentage_of_train_as_validation,\n",
    "                    verbose=False,\n",
    "                    callbacks=[model_checkpoint])\n",
    "end_training = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac3b4352d35eb96",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb766dc32bda14b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T13:14:39.836170Z",
     "start_time": "2024-05-20T13:14:39.723934Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load and evaluate best model\n",
    "best_model_rnn = models.load_model('best_model_RNN.keras')\n",
    "\n",
    "train_loss, train_accuracy = best_model_rnn.evaluate(X_train, y_train)\n",
    "\n",
    "start_evaluate = time.time()\n",
    "test_loss, test_accuracy = best_model_rnn.evaluate(X_test, y_test)\n",
    "end_evaluate = time.time()\n",
    "\n",
    "\n",
    "# Other calcul\n",
    "y_pred = model_rnn.predict(X_test)\n",
    "y_pred_classes = (y_pred > 0.5).astype(int).flatten()\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_classes)\n",
    "class_names = ['Positif', 'Négatif']\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "roc_auc = auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1b888931713a19",
   "metadata": {},
   "source": [
    "## Plot best result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561ae0422286e6a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T13:14:42.943575Z",
     "start_time": "2024-05-20T13:14:41.815553Z"
    }
   },
   "outputs": [],
   "source": [
    "# Result\n",
    "training_time_seconds = end_training - start_training\n",
    "evaluate_time_seconds = end_evaluate - start_evaluate\n",
    "print(f\"\\nNombre total de paramètres : {best_model_rnn.count_params()}\")\n",
    "print(f\"\\nTemps d'entraînement : {training_time_seconds:.3f} secondes.\")\n",
    "print(f\"Temps d'évaluation : {evaluate_time_seconds:.3f} secondes.\")\n",
    "print(f'\\nMoyenne de train_accuracy_vals: {np.mean(train_accuracy) * 100:.2f}%')\n",
    "print(f'Moyenne de train_loss_vals: {np.mean(train_loss) * 100:.2f}%')\n",
    "print(f'\\nMoyenne de test_accuracy_vals: {np.mean(test_accuracy) * 100:.2f}%')\n",
    "print(f'Moyenne de test_loss_vals: {np.mean(test_loss) * 100:.2f}%')\n",
    "print(f'\\nAUC-ROC : {roc_auc * 100:.2f}%')\n",
    "\n",
    "# Plot \n",
    "plt.figure(figsize=(16, 12))\n",
    "    # Training and Validation Accuracy\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.ylim(0, 1)\n",
    "    # Training and Validation Loss\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.ylim(0, 1)\n",
    "    # Confusion Matrix\n",
    "plt.subplot(2, 2, 3)\n",
    "sns.heatmap(conf_matrix, annot=True, cmap=\"Blues\", fmt='g', xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.title('Confusion Matrix')\n",
    "    # ROC Curve\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label='ROC curve (AUC = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a490aa48797d56be",
   "metadata": {},
   "source": [
    "## Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc56335aaf5292b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.loadtxt('data/ECG200_TRAIN.tsv', delimiter='\\t')\n",
    "test_data = np.loadtxt('data/ECG200_TEST.tsv', delimiter='\\t')\n",
    "\n",
    "test_data[test_data[:, 0] == -1, 0] = 0\n",
    "X_test, y_test = test_data[:, 1:], test_data[:, 0]\n",
    "X_test = normalize(X_test, axis=1)\n",
    "\n",
    "# Hyperparameters\n",
    "timesteps = 1\n",
    "nb_neurons = 8\n",
    "nb_classes = 1\n",
    "final_activation = 'sigmoid'\n",
    "optimizer_algo = 'adam'\n",
    "cost_function = 'binary_crossentropy'\n",
    "nb_epochs = 500\n",
    "mini_batch_size = 32\n",
    "percentage_of_train_as_validation = 0.2\n",
    "\n",
    "num_splits = 5\n",
    "test_accuracy_vals = []\n",
    "test_loss_vals = []\n",
    "train_accuracy_vals = []\n",
    "train_loss_vals = []\n",
    "\n",
    "for i in range(num_splits) :\n",
    "    train_data_suffled = train_data\n",
    "    np.random.shuffle(train_data_suffled)\n",
    "    train_data_suffled[train_data_suffled[:, 0] == -1, 0] = 0\n",
    "    X_train, y_train = train_data_suffled[:, 1:], train_data_suffled[:, 0]\n",
    "    X_trai = normalize(X_train, axis=1)\n",
    "\n",
    "    # build and compile model\n",
    "    input_shape = (96,1)\n",
    "    input_layer = Input(input_shape)\n",
    "    lstm_layer = LSTM(units=nb_neurons)(input_layer)\n",
    "    output_layer = Dense(units=nb_classes, activation=final_activation)(lstm_layer)\n",
    "    model_rnn = models.Model(inputs=input_layer, outputs=output_layer)\n",
    "    model_rnn.compile(loss=cost_function, optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    model_checkpoint = callbacks.ModelCheckpoint('best_model_RNN.keras', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "    history = model_rnn.fit(X_train, y_train,\n",
    "                        batch_size=mini_batch_size, \n",
    "                        epochs=nb_epochs,\n",
    "                        validation_split=percentage_of_train_as_validation,\n",
    "                        verbose=False,\n",
    "                        callbacks=[model_checkpoint])\n",
    "\n",
    "    # evaluate best model\n",
    "    best_model_rnn = models.load_model('best_model_RNN.keras')\n",
    "    train_loss, train_accuracy = best_model_rnn.evaluate(X_train, y_train)\n",
    "    test_loss, test_accuracy = best_model_rnn.evaluate(X_test, y_test)\n",
    "\n",
    "    test_accuracy_vals.append(test_accuracy)\n",
    "    test_loss_vals.append(test_loss)\n",
    "    train_accuracy_vals.append(train_accuracy)\n",
    "    train_loss_vals.append(train_loss)\n",
    "\n",
    "# Display result\n",
    "print(\"\\nNombre d'essais :\", num_splits)\n",
    "print(f'\\nMoyenne de train_accuracy_vals: {np.mean(train_accuracy_vals) * 100:.2f}%')\n",
    "print(f'Moyenne de train_loss_vals: {np.mean(train_loss_vals) * 100:.2f}%')\n",
    "print(f'\\nMoyenne de test_accuracy_vals: {np.mean(test_accuracy_vals) * 100:.2f}%')\n",
    "print(f'Moyenne de test_loss_vals: {np.mean(test_loss_vals) * 100:.2f}%')\n",
    "print(f'\\tLa variance associée de l\\'accuracy: {np.var(test_accuracy_vals):.6f}')\n",
    "print(f'\\tLa variance associée de la loss: {np.var(test_loss_vals):.6f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
