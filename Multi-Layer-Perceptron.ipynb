{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e619933b9e1de83c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Multi-Layer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6142b3b883c6c5cf",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Importation librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T19:12:24.688166Z",
     "start_time": "2024-05-16T19:12:24.672077Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.utils import normalize, plot_model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras import models, callbacks\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers import legacy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8273bbc1",
   "metadata": {},
   "source": [
    "## Data import and display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359482d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data recovery\n",
    "train_data = np.loadtxt('data/ECG200_TRAIN.tsv', delimiter='\\t')\n",
    "test_data = np.loadtxt('data/ECG200_TEST.tsv', delimiter='\\t')\n",
    "\n",
    "# Show first time series\n",
    "print(\"health:\", train_data[0,0])\n",
    "print(train_data[0,1:])\n",
    "\n",
    "# Show data dimensions\n",
    "print(\"Dimensions des données d'entrainnement:\", train_data.shape)\n",
    "print(\"Dimensions des données de test:\", test_data.shape)\n",
    "\n",
    "# Show first 5 time series\n",
    "nb_series_a_afficher = 5\n",
    "plt.figure(figsize=(27, 7))\n",
    "for i in range(nb_series_a_afficher):\n",
    "    serie_temporelle = train_data[i, 1:]\n",
    "    etat_sante = train_data[i, 0]\n",
    "    \n",
    "    plage_temps = range(len(serie_temporelle))\n",
    "    \n",
    "    plt.subplot(2, nb_series_a_afficher, i+1)\n",
    "    plt.plot(plage_temps, serie_temporelle, label='Série temporelle')\n",
    "    plt.xlabel('Temps')\n",
    "    plt.ylabel('Valeurs')\n",
    "    plt.title(f'Série temporelle {i+1} (Santé: {\"Bon\" if etat_sante == -1 else \"Mauvais\"})')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41f427f6ea3cf99",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb62b622add25e10",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T19:12:24.704170Z",
     "start_time": "2024-05-16T19:12:24.689166Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Normalizer classes\n",
    "train_data[train_data[:, 0] == -1, 0] = 0\n",
    "test_data[test_data[:, 0] == -1, 0] = 0\n",
    "\n",
    "# Separation of training and testing data\n",
    "X_train, y_train = train_data[:, 1:], train_data[:, 0]\n",
    "X_test, y_test = test_data[:, 1:], test_data[:, 0]\n",
    "\n",
    "# Normalize time series between 0 and 1 independently of each other\n",
    "X_train = normalize(X_train, axis=1)\n",
    "X_test = normalize(X_test, axis=1)\n",
    "\n",
    "# Display first data\n",
    "print(\"health:\", y_train[0])\n",
    "print(X_train[0])\n",
    "print(\"Dimensions des données d'entrainnement:\", (X_train.shape, y_train.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75d75eb",
   "metadata": {},
   "source": [
    "## Choice of Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a5c4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layers hyperparameters\n",
    "nb_neurons = 512\n",
    "hidden_activation = 'relu'\n",
    "dropout = 0.2\n",
    "nb_classes = 1\n",
    "final_activation = 'sigmoid'\n",
    "\n",
    "# Compil hyperparameters\n",
    "learning_rate = 0.001\n",
    "optimizer_algo = Adam(learning_rate=learning_rate)\n",
    "cost_function = 'binary_crossentropy'\n",
    "\n",
    "# Execution hyperparameters\n",
    "nb_epochs = 150\n",
    "mini_batch_size = 16\n",
    "percentage_of_train_as_validation = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39741256",
   "metadata": {},
   "source": [
    "## Creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a909a07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "input_shape = (96, )\n",
    "input_layer = Input(input_shape)\n",
    "\n",
    "# Hidden block\n",
    "hidden_layer_1 = Dense(units=nb_neurons, activation=hidden_activation)(input_layer)\n",
    "dropout_1 = Dropout(rate=dropout)(hidden_layer_1)\n",
    "\n",
    "# Output\n",
    "output_layer = Dense(units=nb_classes, activation=final_activation)(dropout_1)\n",
    "\n",
    "model_mlp = models.Model(inputs=input_layer, outputs=output_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3af1a9",
   "metadata": {},
   "source": [
    "## Model compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33acd007ad03ed18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T19:12:24.829990Z",
     "start_time": "2024-05-16T19:12:24.815918Z"
    }
   },
   "outputs": [],
   "source": [
    "model_mlp.compile(loss=cost_function, optimizer=optimizer_algo, metrics=['accuracy'])\n",
    "\n",
    "model_mlp.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c611a2a7",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b576194bfb1e15",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T19:12:28.769634Z",
     "start_time": "2024-05-16T19:12:24.830990Z"
    }
   },
   "outputs": [],
   "source": [
    "# Specify the model checkpoint (to save the best model for each epoch)\n",
    "model_checkpoint = callbacks.ModelCheckpoint('best_model_MLP.keras', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "# Start training\n",
    "start_training = time.time()\n",
    "history = model_mlp.fit(X_train, y_train,\n",
    "                    batch_size=mini_batch_size, \n",
    "                    epochs=nb_epochs,\n",
    "                    validation_split=percentage_of_train_as_validation,\n",
    "                    verbose=False,\n",
    "                    callbacks=[model_checkpoint])\n",
    "end_training = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a67e605",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0e0bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and evaluate best model\n",
    "best_model_mlp = models.load_model('best_model_MLP.keras')\n",
    "\n",
    "train_loss, train_accuracy = best_model_mlp.evaluate(X_train, y_train)\n",
    "\n",
    "start_evaluate = time.time()\n",
    "test_loss, test_accuracy = best_model_mlp.evaluate(X_test, y_test)\n",
    "end_evaluate = time.time()\n",
    "\n",
    "\n",
    "# Other calcul\n",
    "y_pred = model_mlp.predict(X_test)\n",
    "y_pred_classes = (y_pred > 0.5).astype(int).flatten()\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_classes)\n",
    "class_names = ['Positif', 'Négatif']\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "roc_auc = auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c5d8a3",
   "metadata": {},
   "source": [
    "## Plot best result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d352e2f350dcd0cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T19:12:28.926171Z",
     "start_time": "2024-05-16T19:12:28.770635Z"
    }
   },
   "outputs": [],
   "source": [
    "# Result\n",
    "training_time_seconds = end_training - start_training\n",
    "evaluate_time_seconds = end_evaluate - start_evaluate\n",
    "print(f\"\\nNombre total de paramètres : {best_model_mlp.count_params()}\")\n",
    "print(f\"\\nTemps d'entraînement : {training_time_seconds:.3f} secondes.\")\n",
    "print(f\"Temps d'évaluation : {evaluate_time_seconds:.3f} secondes.\")\n",
    "print(f'\\nMoyenne de train_accuracy_vals: {np.mean(train_accuracy) * 100:.2f}%')\n",
    "print(f'Moyenne de train_loss_vals: {np.mean(train_loss) * 100:.2f}%')\n",
    "print(f'\\nMoyenne de test_accuracy_vals: {np.mean(test_accuracy) * 100:.2f}%')\n",
    "print(f'Moyenne de test_loss_vals: {np.mean(test_loss) * 100:.2f}%')\n",
    "print(f'\\nAUC-ROC : {roc_auc * 100:.2f}%')\n",
    "\n",
    "# Plot \n",
    "plt.figure(figsize=(16, 12))\n",
    "    # Training and Validation Accuracy\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.ylim(0, 1)\n",
    "    # Training and Validation Loss\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.ylim(0, 1)\n",
    "    # Confusion Matrix\n",
    "plt.subplot(2, 2, 3)\n",
    "sns.heatmap(conf_matrix, annot=True, cmap=\"Blues\", fmt='g', xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.title('Confusion Matrix')\n",
    "    # ROC Curve\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label='ROC curve (AUC = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679a8cd0",
   "metadata": {},
   "source": [
    "## Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7955b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.loadtxt('data/ECG200_TRAIN.tsv', delimiter='\\t')\n",
    "test_data = np.loadtxt('data/ECG200_TEST.tsv', delimiter='\\t')\n",
    "\n",
    "test_data[test_data[:, 0] == -1, 0] = 0\n",
    "X_test, y_test = test_data[:, 1:], test_data[:, 0]\n",
    "X_test = normalize(X_test, axis=1)\n",
    "\n",
    "# Hyperparameters\n",
    "nb_neurons = 512\n",
    "hidden_activation = 'relu'\n",
    "dropout = 0.2\n",
    "nb_classes = 1\n",
    "final_activation = 'sigmoid'\n",
    "learning_rate = 0.001\n",
    "optimizer_algo = legacy.Adam(learning_rate=learning_rate)\n",
    "cost_function = 'binary_crossentropy'\n",
    "nb_epochs = 150\n",
    "mini_batch_size = 16\n",
    "percentage_of_train_as_validation = 0.2\n",
    "\n",
    "num_splits = 5\n",
    "test_accuracy_vals = []\n",
    "test_loss_vals = []\n",
    "train_accuracy_vals = []\n",
    "train_loss_vals = []\n",
    "\n",
    "for i in range(num_splits) :\n",
    "    train_data_suffled = train_data\n",
    "    np.random.shuffle(train_data_suffled)\n",
    "    train_data_suffled[train_data_suffled[:, 0] == -1, 0] = 0\n",
    "    X_train, y_train = train_data_suffled[:, 1:], train_data_suffled[:, 0]\n",
    "    X_trai = normalize(X_train, axis=1)\n",
    "\n",
    "    # build and compile model\n",
    "    input_shape = (96, )\n",
    "    input_layer = Input(input_shape)\n",
    "    hidden_layer_1 = Dense(units=nb_neurons, activation=hidden_activation)(input_layer)\n",
    "    dropout_1 = Dropout(rate=dropout)(hidden_layer_1)\n",
    "    output_layer = Dense(units=nb_classes, activation=final_activation)(dropout_1)\n",
    "    model_mlp = models.Model(inputs=input_layer, outputs=output_layer)\n",
    "    model_mlp.compile(loss=cost_function, optimizer=optimizer_algo, metrics=['accuracy'])\n",
    "\n",
    "    model_checkpoint = callbacks.ModelCheckpoint('best_model_MLP.keras', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "    history = model_mlp.fit(X_train, y_train,\n",
    "                        batch_size=mini_batch_size, \n",
    "                        epochs=nb_epochs,\n",
    "                        validation_split=percentage_of_train_as_validation,\n",
    "                        verbose=False,\n",
    "                        callbacks=[model_checkpoint])\n",
    "\n",
    "    # evaluate best model\n",
    "    best_model_mlp = models.load_model('best_model_MLP.keras')\n",
    "    train_loss, train_accuracy = best_model_mlp.evaluate(X_train, y_train)\n",
    "    test_loss, test_accuracy = best_model_mlp.evaluate(X_test, y_test)\n",
    "\n",
    "    test_accuracy_vals.append(test_accuracy)\n",
    "    test_loss_vals.append(test_loss)\n",
    "    train_accuracy_vals.append(train_accuracy)\n",
    "    train_loss_vals.append(train_loss)\n",
    "\n",
    "# Display result\n",
    "print(\"\\nNombre d'essais :\", num_splits)\n",
    "print(f'\\nMoyenne de train_accuracy_vals: {np.mean(train_accuracy_vals) * 100:.2f}%')\n",
    "print(f'Moyenne de train_loss_vals: {np.mean(train_loss_vals) * 100:.2f}%')\n",
    "print(f'\\nMoyenne de test_accuracy_vals: {np.mean(test_accuracy_vals) * 100:.2f}%')\n",
    "print(f'Moyenne de test_loss_vals: {np.mean(test_loss_vals) * 100:.2f}%')\n",
    "print(f'\\tLa variance associée de l\\'accuracy: {np.var(test_accuracy_vals):.6f}')\n",
    "print(f'\\tLa variance associée de la loss: {np.var(test_loss_vals):.6f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
